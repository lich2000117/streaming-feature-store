# Streaming Feature Store - Project Structure

## Overview

This project follows a **centralized Docker Compose approach** with **distributed Dockerfiles** for optimal development and production deployment. All services are orchestrated through a single `docker-compose.yml` file using Docker Compose profiles.

## Architecture Decision

**âœ… Chosen Approach: Centralized Compose + Distributed Dockerfiles**

```
Project Root/
â”œâ”€â”€ infra/
â”‚   â””â”€â”€ docker-compose.yml          # ğŸ¯ SINGLE SOURCE OF TRUTH
â”œâ”€â”€ service1/
â”‚   â””â”€â”€ Dockerfile                  # Service-specific build
â”œâ”€â”€ service2/
â”‚   â””â”€â”€ Dockerfile                  # Service-specific build
â””â”€â”€ Makefile                        # Uses centralized compose
```

**Why This Approach:**
1. **Single source of truth** for service orchestration
2. **Service isolation** with individual Dockerfiles
3. **Profile-based deployment** for different environments
4. **Consistent with your existing Makefile** commands
5. **Production-ready** with proper dependencies and health checks

## Project Structure

```
streaming-feature-store/
â”œâ”€â”€ ğŸ“ infra/                       # Infrastructure & Orchestration
â”‚   â””â”€â”€ docker-compose.yml          # ğŸ¯ All services defined here
â”‚
â”œâ”€â”€ ğŸ“ generators/                  # Event Generation
â”‚   â”œâ”€â”€ Dockerfile                  # Synthetic data generators
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ txgen.py
â”‚   â””â”€â”€ clickgen.py
â”‚
â”œâ”€â”€ ğŸ“ streaming/                   # Stream Processing
â”‚   â”œâ”€â”€ Dockerfile                  # Feature engineering pipeline
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ stream_processor.py
â”‚
â”œâ”€â”€ ğŸ“ inference/                   # ML Serving
â”‚   â”œâ”€â”€ Dockerfile                  # FastAPI inference service
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ features.py
â”‚   â””â”€â”€ models.py
â”‚
â”œâ”€â”€ ğŸ“ training/                    # ML Training
â”‚   â”œâ”€â”€ Dockerfile                  # Training pipeline
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ train.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ datasets.py
â”‚   â”œâ”€â”€ models.py
â”‚   â””â”€â”€ outputs/                    # Model artifacts
â”‚
â”œâ”€â”€ ğŸ“ feast/                       # Feature Store
â”‚   â”œâ”€â”€ Dockerfile                  # Feast server
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ feature_store.yaml
â”‚
â”œâ”€â”€ ğŸ“ monitoring/                  # Observability
â”‚   â”œâ”€â”€ prometheus/                 # Metrics collection
â”‚   â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â”‚   â”œâ”€â”€ alert_rules.yml
â”‚   â”‚   â””â”€â”€ recording_rules.yml
â”‚   â”œâ”€â”€ grafana/                    # Visualization
â”‚   â”‚   â”œâ”€â”€ dashboards/
â”‚   â”‚   â””â”€â”€ provisioning/
â”‚   â””â”€â”€ blackbox/                   # Endpoint monitoring
â”‚       â””â”€â”€ config.yml
â”‚
â”œâ”€â”€ ğŸ“ schemas/                     # Data Contracts
â”‚   â”œâ”€â”€ transactions.v1.avsc
â”‚   â”œâ”€â”€ clicks.v1.avsc
â”‚   â””â”€â”€ validate_schemas.py
â”‚
â”œâ”€â”€ Makefile                        # ğŸ¯ Uses infra/docker-compose.yml
â”œâ”€â”€ DesignDoc.md
â””â”€â”€ README.md
```

## Docker Compose Profiles

All services use **Docker Compose profiles** for environment-specific deployments:

### Core Infrastructure (Always Running)
```yaml
services:
  kafka:           # Message broker
  schema-registry: # Schema management  
  redis:           # Feature store
  mlflow:          # ML lifecycle management
```

### Service Profiles
```yaml
profiles:
  - generators: [txn-generator, click-generator]
  - streaming:  [stream-processor]
  - inference:  [inference-api]
  - feast:      [feast-server]
  - training:   [training-job]
  - monitoring: [prometheus, grafana, redis-exporter, node-exporter, blackbox-exporter]
  - all:        [everything above]
```

## Makefile Commands

All commands use the **centralized compose file**:

```bash
# Infrastructure
make up              # Start core services
make down            # Stop all services

# Service Management  
make generate        # Start event generators
make stream          # Start stream processing
make serve           # Start inference API
make feast_up        # Start feature store
make train           # Run ML training
make monitor         # Start monitoring stack

# Complete Platform
make demo            # Start everything for demo
make up-all          # Start all profiles

# Operations
make health          # Check service health
make logs-api        # View API logs
make inspect         # View data flow
make test-api        # Test API endpoints
```

## Development Workflow

### 1. Local Development
```bash
# Start core infrastructure
make up

# Start specific services as needed
make serve           # For API development
make monitor         # For observability
make generate        # For data generation
```

### 2. Full System Testing
```bash
# Start everything
make demo

# Test end-to-end
make test-api
make inspect
make health
```

### 3. Production Deployment
```bash
# All services with monitoring
make up-all
```

## Service Dependencies

The compose file defines **proper dependency chains**:

```yaml
inference-api:
  depends_on:
    redis:
      condition: service_healthy

stream-processor:
  depends_on:
    kafka:
      condition: service_healthy
    redis:
      condition: service_healthy

monitoring:
  depends_on:
    - redis
    - prometheus
```

## Benefits of This Architecture

### âœ… Development Benefits
1. **Service Isolation**: Each service has its own Dockerfile
2. **Fast Iteration**: Only rebuild changed services
3. **Easy Testing**: Start individual services for testing
4. **Clear Boundaries**: Service responsibilities are well-defined

### âœ… Operations Benefits
1. **Single Orchestration**: One compose file to rule them all
2. **Profile-based Deployment**: Deploy only what you need
3. **Consistent Commands**: Makefile abstracts complexity
4. **Health Checks**: Proper service startup ordering
5. **Volume Management**: Persistent data across restarts

### âœ… Production Benefits
1. **Scalable**: Individual services can be scaled
2. **Monitored**: Complete observability stack
3. **Reliable**: Health checks and restart policies
4. **Maintainable**: Clear service boundaries and configs

## Configuration Management

### Environment Variables
```yaml
# Service-specific configs in docker-compose.yml
inference-api:
  environment:
    - REDIS_HOST=redis
    - MODEL_VERSION=v1
    - LOG_LEVEL=INFO

training-job:
  environment:
    - MLFLOW_TRACKING_URI=http://mlflow:5001
    - REDIS_HOST=redis
```

### Volume Mounts
```yaml
# Configuration files mounted from host
prometheus:
  volumes:
    - ../monitoring/prometheus:/etc/prometheus

# Persistent data volumes
grafana:
  volumes:
    - grafana_data:/var/lib/grafana
```

## Monitoring Integration

The monitoring stack is **fully integrated** into the main compose file:

```yaml
# Prometheus scrapes all services automatically
prometheus:
  # Scrapes: inference-api:8080/metrics
  # Scrapes: redis-exporter:9121/metrics
  # Scrapes: node-exporter:9100/metrics

grafana:
  # Auto-loads dashboards from monitoring/grafana/
  # Connects to Prometheus automatically
```

## Migration from Separate Compose Files

**âœ… What Was Fixed:**
1. **Removed**: `monitoring/docker-compose.monitoring.yml` (duplicate)
2. **Enhanced**: `infra/docker-compose.yml` with complete monitoring stack
3. **Aligned**: All Makefile commands use centralized approach
4. **Added**: Missing exporters (redis-exporter, node-exporter, blackbox-exporter)
5. **Improved**: Prometheus configuration with alert/recording rules

**âœ… Result:**
- **Single source of truth**: `infra/docker-compose.yml`
- **Consistent commands**: All Makefile targets work correctly
- **Complete monitoring**: All observability components included
- **Production-ready**: Health checks, dependencies, and volumes

## Best Practices Followed

1. **ğŸ¯ Centralized Orchestration**: Single compose file for all services
2. **ğŸ“¦ Service Isolation**: Individual Dockerfiles per service
3. **ğŸ”§ Profile-based Deployment**: Environment-specific service groups
4. **ğŸ¥ Health Checks**: Proper service startup ordering
5. **ğŸ“Š Complete Observability**: Integrated monitoring stack
6. **ğŸ”’ Production Security**: Non-root containers and proper networking
7. **ğŸ“š Clear Documentation**: Comprehensive README and structure docs

This architecture provides the optimal balance of **development flexibility** and **production reliability** while maintaining clear service boundaries and operational simplicity.
