# fixes: make kafka healthcheck target the in-network broker; add sane restart policies

services:
  kafka:
    image: docker.redpanda.com/redpandadata/redpanda:v23.3.3
    container_name: kafka
    command: ["redpanda","start","--overprovisioned","--smp","1","--memory","1G","--reserve-memory","0M","--node-id","0","--check=false","--kafka-addr","0.0.0.0:9092","--advertise-kafka-addr","kafka:9092"]
    ports: [ "9092:9092", "9644:9644" ]
    healthcheck:
      # explicitly tell rpk which broker to ping (avoid localhost flakiness)
      test: ["CMD-SHELL", "rpk cluster info -X brokers=kafka:9092 >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  schema-registry:
    image: confluentinc/cp-schema-registry:7.7.0
    container_name: schema-registry
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:9092"
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: "PLAINTEXT"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
    ports: [ "8081:8081" ]
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8081/subjects"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: redis
    ports: [ "6379:6379" ]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  txn-generator:
    build:
      context: ..
      dockerfile: generators/Dockerfile
    container_name: txn-generator
    command: ["generators/txgen.py","--events-per-second","3","--duration","3600","--bootstrap-servers","kafka:9092"]
    depends_on:
      kafka:
        condition: service_healthy
    restart: on-failure
    profiles: ["generators", "all"]

  click-generator:
    build:
      context: ..
      dockerfile: generators/Dockerfile
    container_name: click-generator
    command: ["generators/clickgen.py","--events-per-second","4","--duration","3600","--bootstrap-servers","kafka:9092"]
    depends_on:
      kafka:
        condition: service_healthy
    restart: on-failure
    profiles: ["generators", "all"]


  # === STREAM PROCESSING ===
  stream-processor:
    build:
      context: ..
      dockerfile: streaming/Dockerfile
    container_name: stream-processor
    environment:
      - KAFKA_SERVERS=kafka:9092
      - REDIS_HOST=redis
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    profiles: ["streaming", "all"]

  # === INFERENCE SERVICE ===
  inference-api:
    build:
      context: ..
      dockerfile: inference/Dockerfile
    container_name: inference-api
    ports: [ "8080:8080" ]
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MODEL_VERSION=v1
      - LOG_LEVEL=INFO
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    profiles: ["inference", "all"]

  # === FEATURE STORE ===
  feast-server:
    build:
      context: ..
      dockerfile: feast/Dockerfile
    container_name: feast-server
    ports: [ "6566:6566" ]
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      redis:
        condition: service_healthy
    profiles: ["feast", "all"]

  # === ML TRAINING ===
  training-job:
    build:
      context: ..
      dockerfile: training/Dockerfile
    container_name: training-job
    environment:
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ../training/models:/app/models
      - ../training/artifacts:/app/artifacts
    depends_on:
      redis:
        condition: service_healthy
      mlflow:
        condition: service_healthy
    profiles: ["training", "ml", "all"]

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.16.0
    container_name: mlflow
    command: mlflow server --host 0.0.0.0 --port 5000 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlartifacts
    volumes: 
      - mlflow_data:/mlartifacts
    ports: [ "5000:5000" ]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    profiles: ["ml", "all"]

  # === MONITORING ===
  prometheus:
    image: prom/prometheus:v2.53.1
    container_name: prometheus
    ports: [ "9090:9090" ]
    volumes:
      - ../monitoring/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    profiles: ["monitoring", "all"]

  grafana:
    image: grafana/grafana:11.1.0
    container_name: grafana
    ports: [ "3000:3000" ]
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ../monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ../monitoring/grafana/provisioning:/etc/grafana/provisioning
    depends_on: [ prometheus ]
    profiles: ["monitoring", "all"]

# === NETWORKING ===
networks:
  default:
    driver: bridge
    name: streaming-feature-store

# === PERSISTENT VOLUMES ===
volumes:
  mlflow_data:
  prometheus_data:
  grafana_data:
