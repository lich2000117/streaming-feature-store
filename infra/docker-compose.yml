# fixes: make kafka healthcheck target the in-network broker; add sane restart policies

services:

  # === CORE INFRASTRUCTURE ===
  kafka:
    image: docker.redpanda.com/redpandadata/redpanda:v23.3.3
    container_name: kafka
    command: ["redpanda","start","--overprovisioned","--smp","1","--memory","1G","--reserve-memory","0M","--node-id","0","--check=false","--kafka-addr","0.0.0.0:9092","--advertise-kafka-addr","kafka:9092"]
    ports: [ "9092:9092", "9644:9644" ]
    healthcheck:
      # explicitly tell rpk which broker to ping (avoid localhost flakiness)
      test: ["CMD-SHELL", "rpk cluster info -X brokers=kafka:9092 >/dev/null 2>&1 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  schema-registry:
    image: confluentinc/cp-schema-registry:7.7.0
    container_name: schema-registry
    environment:
      SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: "kafka:9092"
      SCHEMA_REGISTRY_KAFKASTORE_SECURITY_PROTOCOL: "PLAINTEXT"
      SCHEMA_REGISTRY_HOST_NAME: schema-registry
      SCHEMA_REGISTRY_LISTENERS: "http://0.0.0.0:8081"
    ports: [ "8081:8081" ]
    depends_on:
      kafka:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-fsS", "http://localhost:8081/subjects"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    container_name: redis
    ports: [ "6379:6379" ]
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 10
    restart: unless-stopped
  
  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.16.0
    container_name: mlflow
    command: mlflow server --host 0.0.0.0 --port 5001 --backend-store-uri sqlite:///mlflow.db --default-artifact-root /mlartifacts
    volumes: 
      - mlflow_data:/mlartifacts
    ports: [ "5001:5001" ]
    healthcheck:
      test: ["CMD", "python", "-c", "import socket; s=socket.socket(); s.connect(('127.0.0.1',5001))"]
      interval: 10s
      timeout: 10s
      retries: 5



  # MLflow metrics exporter
  mlflow-metrics:
    build:
      context: ..
      dockerfile: training/Dockerfile
    container_name: mlflow-metrics
    ports: [ "8568:8568" ]
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5001
    command: ["python", "mlflow_metrics.py", "--port", "8568", "--tracking-uri", "http://mlflow:5001"]
    depends_on:
      mlflow:
        condition: service_healthy
    profiles: ["monitoring", "all"]


  # === GENERATORS ===
  txn-generator:
    build:
      context: ..
      dockerfile: generators/Dockerfile
    container_name: txn-generator
    ports: [ "8001:8001" ]  # Expose metrics port
    command: ["generators/txgen.py","--events-per-second","10","--duration","3600","--bootstrap-servers","kafka:9092","--metrics-port","8001", "--fraud-rate","0.4"]
    depends_on:
      kafka:
        condition: service_healthy
    restart: on-failure
    profiles: ["generators", "all"]

  click-generator:
    build:
      context: ..
      dockerfile: generators/Dockerfile
    container_name: click-generator
    ports: [ "8002:8002" ]  # Expose metrics port
    command: ["generators/clickgen.py","--events-per-second","4","--duration","3600","--bootstrap-servers","kafka:9092","--metrics-port","8002"]
    depends_on:
      kafka:
        condition: service_healthy
    restart: on-failure
    profiles: ["generators", "all"]


  # === STREAM PROCESSING ===
  stream-processor:
    build:
      context: ..
      dockerfile: streaming/Dockerfile
    container_name: stream-processor
    ports: [ "8000:8000" ]  # Expose metrics port
    environment:
      - KAFKA_SERVERS=kafka:9092
      - REDIS_HOST=redis
      - SCHEMA_REGISTRY_URL=http://schema-registry:8081
      - METRICS_PORT=8000
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
    profiles: ["streaming", "all"]

  # === INFERENCE SERVICE ===
  inference-api:
    build:
      context: ..
      dockerfile: inference/Dockerfile
    container_name: inference-api
    ports: [ "8080:8080" ]
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - MODEL_VERSION=v1
      - LOG_LEVEL=DEBUG
    depends_on:
      redis:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
    profiles: ["inference", "all"]

  # === FEATURE STORE ===
  feast-server:
    build:
      context: ..
      dockerfile: feast/Dockerfile
    container_name: feast-server
    ports: [ "6566:6566", "8567:8567" ]  # Add metrics port
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      redis:
        condition: service_healthy
    profiles: ["feast", "all"]

  # === ML TRAINING ===
  training-job:
    build:
      context: ..
      dockerfile: training/Dockerfile
    container_name: training-job
    environment:
      - REDIS_HOST=redis
      - MLFLOW_TRACKING_URI=http://mlflow:5001
    volumes:
      - ../training/outputs:/app/training/outputs
      - ../training/models:/app/training/models
    depends_on:
      redis:
        condition: service_healthy
    profiles: ["training", "all"]


  # === MONITORING ===
  prometheus:
    image: prom/prometheus:v2.53.1
    container_name: prometheus
    ports: [ "9090:9090" ]
    volumes:
      - ../monitoring/prometheus:/etc/prometheus
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=30d'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
      - '--web.enable-lifecycle'
      - '--web.enable-admin-api'
    profiles: ["monitoring", "all"]

  grafana:
    image: grafana/grafana:11.1.0
    container_name: grafana
    ports: [ "3000:3000" ]
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin123
    volumes:
      - grafana_data:/var/lib/grafana
      - ../monitoring/grafana/dashboards:/var/lib/grafana/dashboards
      - ../monitoring/grafana/provisioning:/etc/grafana/provisioning
    depends_on: [ prometheus ]
    profiles: ["monitoring", "all"]

  redis-exporter:
    image: oliver006/redis_exporter:v1.58.0
    container_name: redis-exporter
    ports: [ "9121:9121" ]
    environment:
      - REDIS_ADDR=redis://redis:6379
    command:
      - '--redis.addr=redis://redis:6379'
      - '--web.listen-address=0.0.0.0:9121'
    depends_on:
      redis:
        condition: service_healthy
    profiles: ["monitoring", "all"]

  node-exporter:
    image: prom/node-exporter:v1.7.0
    container_name: node-exporter
    ports: [ "9100:9100" ]
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.rootfs=/rootfs'
      - '--path.sysfs=/host/sys'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($$|/)'
    profiles: ["monitoring", "all"]

  blackbox-exporter:
    image: prom/blackbox-exporter:v0.24.0
    container_name: blackbox-exporter
    ports: [ "9115:9115" ]
    volumes:
      - ../monitoring/blackbox:/etc/blackbox_exporter
    command:
      - '--config.file=/etc/blackbox_exporter/config.yml'
    profiles: ["monitoring", "all"]

# === NETWORKING ===
networks:
  default:
    driver: bridge
    name: streaming-feature-store

# === PERSISTENT VOLUMES ===
volumes:
  mlflow_data:
  prometheus_data:
  grafana_data:
